# SCI for Web Assembly - Participant Handout

## **Summary**

The SCI for Web Assembly is an **asynchronous, consensus-driven process** designed to develop the industry standard for measuring website carbon emissions. This assembly operates through **rapid 2-day email cycles** with GitHub transparency and selective live sessions only when objections cannot be resolved asynchronously.

**SCI for Web details:** [https://assemblies.greensoftware.foundation/sci-for-web](https://assemblies.greensoftware.foundation/sci-for-web)

---

## **Key Dates & Timeline**

* **Pre-Assembly Questionnaire:** September 15-22, 2025 (1 week)
* **Consensus Building:** September 22 - December 1, 2025 (10 weeks)
  * **Scope Definition:** Sept 22 - Oct 6 (2 weeks)
  * **Quality Rubric:** Oct 6 - Oct 20 (2 weeks) 
  * **Target Personas:** Oct 20 - Nov 3 (2 weeks)
  * **Behavioral Incentives:** Nov 3 - Nov 17 (2 weeks)
  * **Comparative Analysis:** Nov 17 - Dec 1 (2 weeks)
* **Report Finalization:** December 1-8, 2025 (1 week)
* **Total Duration:** Approximately 13 weeks
* **Timeline Flexibility:** If consensus is reached faster on any area (e.g., 1 week instead of 2), the overall timeline may be shortened accordingly
* **Capacity:** Maximum 20 participants
* **Time Commitment:** 30 minutes every 2 days, work on your schedule

---

## **The Async-First Process**

### **Core 2-Day Cycle**
Every consensus area follows this rapid cycle:

**Type 1: Question Emails**
1. **Monday:** Engineered question email sent to all participants
2. **Wednesday:** Free-form response deadline (2 days to respond - as detailed and wordy as you want)

**Type 2: Synthesis Emails**  
3. **Wednesday:** AI synthesis email sent back containing:
   - Areas of agreement across all responses
   - Areas of disagreement with specific participant positions
   - Outlier viewpoints tagged to individuals
   - Candidate statement for consensus
4. **Friday:** Endorse/Consent/Object responses due
5. **Repeat** synthesis cycles until consensus or escalate to live call

### **Why 2-Day Cycles?**
- **Maintains momentum** - no waiting weeks for responses
- **Global accessibility** - enough time across all time zones  
- **Forces focus** - prevents overthinking and analysis paralysis
- **Creates urgency** - drives engagement and decision-making

### **Sequential Consensus Areas**
Each area **must** be completed before moving to the next due to dependencies:

1. **Scope Definition** → *What applications are in/out of scope?*
2. **Quality Rubric** → *How do we evaluate success within that scope?*
3. **Target Personas** → *Who adopts this within scope for quality goals?*
4. **Behavioral Incentives** → *What specific behaviors should personas change?*
5. **Comparative Analysis** → *How do existing approaches measure against our framework?*

---

## **What Makes This Different**

### **Boundary-Finding Focus**
We're not seeking broad agreement - we're finding the **edges of boundaries**:
- Where does "web application" end and "API" begin?
- Which personas are **essential** vs nice-to-have?  
- What quality criteria are **mandatory** vs optional?

### **Engineered Questions**
Each question is crafted to surface disagreement through:
- **Opposing viewpoints** built into the question
- **Edge cases** that force boundary decisions
- **Artificial constraints** (e.g., "Pick only 3 personas")
- **Implementation specifics** not just philosophy

### **Two Types of Email Responses**

**Question Email Responses:**
- **Free-form response** to the question asked
- **Encourage detailed, wordy responses** - more content helps AI synthesis
- **No structure required** - just respond naturally to the question
- **No endorse/consent/object** needed at this stage

**Synthesis Email Responses:**
Every synthesis includes a **candidate statement** you can:
- **ENDORSE** - Actively support and advocate for (no rationale required)
- **CONSENT** - Can live with, though not ideal (no rationale required)  
- **OBJECT** - Cannot proceed without changes + **must explain what needs to change**

---

## **Participation Format**

### **Pre-Assembly Materials & Questionnaire (1 Week)**
**September 8-15, 2025**

Before the assembly begins, you will receive:
- **Pre-Assembly Questionnaire** (5 questions, 200 words each) - Separate questionnaire document
- **Research Note** - GSF Head of Research & Development's analysis of current state-of-the-art in web carbon measurement, existing specifications, methodologies, and tools
- **This Participant Handout** - Process guide and expectations

*Response deadline: September 15, 2025*

### **Consensus Building Phases (8 Weeks)**

#### **Phase 1: Scope Definition (2 Weeks)**
**September 22 - October 6, 2025**

**Goal:** Crystal-clear boundaries for when to use SCI for Web vs other SCI specs

**Key Boundary Questions:**
- Single-page applications vs multi-page applications?
- Client-side rendering vs server-side rendering?
- Progressive web apps vs native mobile apps?
- Web APIs called by websites vs standalone API services?
- AdTech integrated in websites vs standalone AdTech platforms?

**Success Criteria:** Clear in-scope/out-of-scope statement with edge cases resolved

#### **Phase 2: Quality Rubric (2 Weeks)**  
**October 6-20, 2025**

**Goal:** Prioritized framework for evaluating SCI for Web effectiveness

**Key Prioritization Questions:**
- Measurement accuracy vs implementation simplicity?
- Real-time measurement vs periodic assessment?
- Cross-browser consistency vs platform optimization?
- Developer usability vs procurement requirements?

**Success Criteria:** Ranked quality criteria with clear evaluation methods

#### **Phase 3: Target Personas (2 Weeks)**
**October 20 - November 3, 2025**

**Goal:** Essential adopter categories with specific behavioral targets

**Key Persona Questions:**
- Frontend developers vs full-stack developers vs DevOps?
- Browser vendors vs hosting providers vs CDN operators?
- Enterprise procurement vs startup teams vs open source maintainers?
- **Constraint:** Maximum 5 primary personas allowed

**Success Criteria:** Persona-behavior matrix showing who does what

#### **Phase 4: Behavioral Incentives (2 Weeks)**
**November 3-17, 2025**

**Goal:** Specific behaviors SCI for Web should drive within defined scope

**Key Incentive Questions:**
- Smaller bundle sizes vs faster loading vs fewer requests?
- Edge computing vs centralized hosting vs hybrid approaches?
- Progressive enhancement vs single-page app optimization?
- **Constraint:** Maximum 8 priority behaviors allowed

**Success Criteria:** Ranked behavior list with persona mappings

#### **Phase 5: Comparative Analysis (2 Weeks)**
**November 17 - December 1, 2025**

**Goal:** Evaluate existing approaches against our consensus framework

**Key Analysis Questions:**
- How do current carbon measurement tools align with our scope definition?
- Which existing solutions meet our quality rubric requirements?
- What gaps exist in current approaches for our target personas?
- How well do existing tools drive our prioritized behavioral incentives?

**Success Criteria:** Comprehensive analysis of existing landscape against consensus framework

### **Report Finalization (1 Week)**
**December 1-8, 2025**

Consolidate all consensus decisions into final Assembly Report for publication.

## **How to Participate**

### **Question Email Responses**
When you receive a question email:
- **Reply directly to the email** with your thoughts
- **Be as detailed and wordy as you want** - more tokens help AI synthesis
- **No specific format required** - just respond naturally
- **Submit by the stated deadline** (usually 2 days)

### **Synthesis Email Responses**  
When you receive a synthesis email with candidate statement:
- **Reply with:** `ENDORSE`, `CONSENT`, or `OBJECT`
- **For ENDORSE/CONSENT:** No additional explanation required (though optional)
- **For OBJECT:** You MUST explain what needs to change for you to move to consent/endorse

### **Object Response Requirements**
If you object, your response must explain:
- **What specifically you object to** in the candidate statement
- **What needs to change** for you to move to consent or endorse  
- **The path forward** you see for reaching consensus
- **Your reasoning** - you must be prepared to defend your objection

**Important:** Objecting is not casual. If you object, you're committing to help find a solution and participate in resolution discussions.

### **Objection Resolution Process**

1. **Object via synthesis email response** with detailed rationale of what needs to change
2. **Additional synthesis rounds** incorporating all objection feedback into new candidate statements
3. **Still objecting after multiple rounds?** → Mandatory live call scheduled
4. **Live session attendance required** for people who endorsed AND people who objected
5. **No consensus after 2 weeks?** → Proceed to supermajority vote
6. **Vote outcome becomes final decision** and process moves to next consensus area

---

## **Meeting Philosophy**

### **Standing Bi-Weekly Meetings**
- **Reserved in your calendar** for full assembly duration
- **Used ONLY for objection resolution** - not routine progress
- **Mandatory attendance** if you've objected to the topic
- **Optional attendance** for non-objecting participants
- **72-hour notice** required for activation

### **No Regular Meetings**
- Primary work happens via **email + GitHub**
- **Face-to-face interaction** only when async breaks down
- **Global time zone friendly** - work on your schedule
- **Documentation-driven** process with full transparency

---

## **Tools & Communication**

### **Primary Channel: Email**
- Structured question delivery every 2 days
- Response collection with clear deadlines  
- Synthesis summaries with candidate statements
- Objection notices and resolution coordination

### **Documentation: GitHub** 
- All responses published with attribution
- Complete decision audit trail maintained
- Draft report.md updated in real-time
- Pull request comments for retrospective changes

### **Escalation: Zoom + Miro**
- Live objection resolution sessions
- Visual collaboration for complex disagreements
- Recorded for absent participants
- Used sparingly to maintain async benefits

---

## **The Living Report**

### **REPORT.md File**
- **Every consensus decision** is added to the `REPORT.md` file after consensus is reached
- **Updated throughout assembly** as each consensus area completes
- **Published publicly** only after the assembly is fully complete to GSF membership
- **Not the specification** - this report drives what the specification will be
- **Conversations remain private** - only consensus decisions are published

### **Publication Timeline**
- **Scope consensus** → Added to REPORT.md
- **Quality rubric consensus** → Added to REPORT.md  
- **Persona consensus** → Added to REPORT.md
- **Behavioral incentives consensus** → Added to REPORT.md
- **Comparative analysis consensus** → Added to REPORT.md
- **Assembly completion** → REPORT.md published publicly to GSF membership and broader community

---

## **Participant Expectations**

### **Your Commitment**
- **Response discipline:** 2-day turnaround on all questions
- **Boundary focus:** Help find edges rather than seek broad agreement  
- **Implementation perspective:** Consider real-world deployment challenges
- **Consensus support:** Honor agreed decisions even if not your preference
- **GitHub engagement:** Review others' responses and synthesis summaries

### **What We Provide**
- **Structured process:** Clear methodology preventing deadlock
- **Question engineering:** Crafted to surface productive disagreement
- **AI synthesis:** Rapid processing of responses into actionable insights
- **Escalation support:** Live facilitation when async reaches limits
- **Documentation:** Complete record of all decisions and rationale

---

## **Success Metrics**

### **Process Success**
- Average 3-5 cycles per consensus area (rapid convergence)
- <20% of topics require live objection sessions  
- 100% participant response rate within 2-day windows
- Clear consensus achieved on all 4 major areas

### **Content Success**  
- Sharp scope boundaries distinguishing SCI for Web from other specs
- Implementable quality framework with measurable criteria
- Actionable behavioral incentives mapped to specific personas
- Foundation ready for formal specification development

---

## **FAQ**

**Q: What if I miss a 2-day response deadline?**
A: Contact [assemblies@greensoftware.foundation](mailto:assemblies@greensoftware.foundation) immediately. Synthesis proceeds without late responses, but you can still participate in subsequent rounds.

**Q: Do I need to follow a specific format when responding to questions?**
A: No format required for question emails - just respond naturally and be as detailed as you want. For synthesis emails, just reply with ENDORSE/CONSENT/OBJECT.

**Q: What if I want to object but don't have a complete alternative solution?**
A: You don't need a complete alternative, but you must explain what needs to change for you to move to consent/endorse. Focus on what's wrong and what direction would work better.

**Q: Can I change my position between cycles?**
A: Yes, until final consensus. Each synthesis round is a fresh opportunity to endorse, consent, or object based on the updated candidate statement.

**Q: What happens if I object but can't attend the live session?**
A: Objection sessions are mandatory for objectors. If you can't attend, you should either withdraw your objection or designate someone to represent your position.

**Q: How binding are the report.md consensus decisions?**
A: Very binding. Each consensus decision is immediately published and becomes the foundation for specification development. You're committing to support these outcomes.

**Q: What's the difference between this report and the actual specification?**
A: The report documents our consensus decisions and becomes the foundation for future specification development. The actual technical specification will be developed later by ongoing working groups.

---

## **Contact & Support**

- **Process Questions:** [assemblies@greensoftware.foundation](mailto:assemblies@greensoftware.foundation)
- **Technical Issues:** GitHub issues in the assembly repository
- **Urgent Objections:** Direct contact with Chris Adams (Project Lead)
- **Administrative:** Joseph Cook (Assembly Coordinator)

**Ready to define the future of web carbon measurement?** Your expertise and engagement will shape how the industry measures and reduces website emissions for years to come.